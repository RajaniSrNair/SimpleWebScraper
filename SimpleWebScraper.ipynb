{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNElY284jWzW",
        "outputId": "1a67f830-34cc-4ed1-81d4-f6280f7fd3bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Enter Medium article URL:https://careerfoundry.com/en/blog/data-analytics/web-scraping-guide/\n",
            "Article successfully scraped and saved!\n",
            "Saved at: /content/drive/MyDrive/scraped_articles/article.txt\n"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "import os   # os library helps interact with the os- create folders and work with files on computer\n",
        "import requests   # requests is the standard library for making HTTP requests- vist website using url, retrieves resource/data or perform an action\n",
        "from bs4 import BeautifulSoup  #importing BeautifulSoup 4 library- bs4 package library and BeautifulSoup is the package\n",
        "from google.colab import drive\n",
        "\n",
        "#Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Input: Medium article URL\n",
        "url = input(\"Enter Medium article URL:\")\n",
        "\n",
        "# Send request to the URL\n",
        "response = requests.get(url)   #downloads the webpage and stores it in response\n",
        "\n",
        "# Parse the HTML content using BeautifulSoup\n",
        "soup = BeautifulSoup(response.text, \"html.parser\")    #the website content in response.text is given to BeautifulSoup for parsing and stored in variable soup\n",
        "\n",
        "# Extract all text from the page\n",
        "article_text = soup.get_text()\n",
        "\n",
        "# Create folder named 'scraped_articles' if it does not exist\n",
        "folder_name = \"/content/drive/MyDrive/scraped_articles\"\n",
        "os.makedirs(folder_name, exist_ok=True)\n",
        "\n",
        "\n",
        "# File path\n",
        "file_path = os.path.join(folder_name, \"article.txt\")\n",
        "\n",
        "# Save text to a .txt file\n",
        "with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
        "    file.write(article_text)\n",
        "\n",
        "print(\"Article successfully scraped and saved!\")\n",
        "print(\"Saved at:\", file_path)\n"
      ]
    }
  ]
}